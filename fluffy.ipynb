{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define standard Houdini parameters and load some extra very common libraries... Attention, under Windows Houdini comes with an older version of Python2.7 and numpy, causing for example np.stack to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fluffy Houdini Node\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "node = hou.pwd()\n",
    "geo = node.geometry()\n",
    "# Add code to modify contents of geo.\n",
    "# Use drop down menu to select examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read all the variables from the parameter interface with 'node.parm(...).eval()' and define some generic ones in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global epsilon, beta, rmin,rmax,relativeR,relativepulse,relativetorsion,looseness,pi, nStrands,nHairs,loopiness,th0Default,maxnumberofloosewindings,fluffyness,reducePoints, jitter, mushheight,mushwidth\n",
    "\n",
    "reducePoints=node.parm('reducePoints').eval()\n",
    "rmin=node.parm('radiusx').eval()\n",
    "rmax=node.parm('radiusy').eval()\n",
    "\n",
    "relativepulse=1/node.parm('golven').eval()\n",
    "relativetorsion=node.parm('windingen').eval()\n",
    "\n",
    "nStrands=node.parm('haartjesx').eval()\n",
    "nHairs=node.parm('haartjesy').eval()\n",
    "\n",
    "fluffyness=node.inputs()[1].geometry().attribValue('fluffyness')\n",
    "#fluffyness=node.parm('fluffyness').eval()\n",
    "loopiness=node.parm('loopiness').eval()\n",
    "maxnumberofloosewindings=node.parm('maxloose').eval()\n",
    "looseness=node.parm('looplooseness').eval()\n",
    "\n",
    "flip=node.parm('flip').eval()\n",
    "\n",
    "jitter=node.parm('jitter').eval()\n",
    "\n",
    "mushheight=math.floor(node.parm('mushroomx').eval())\n",
    "mushwidth=node.parm('mushroomy').eval()\n",
    "\n",
    "epsilon=1\n",
    "beta=0.3\n",
    "\n",
    "pi=3.1415926\n",
    "th0Default=np.roll(np.arange(nStrands),3)/nStrands*2*pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need some fairly standard list/geometry operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cycle(ar,shift):\n",
    " return ar.transpose(np.roll(np.arange(len(ar.shape)),shift))\n",
    "def stack(x,y,z):\n",
    " #for lower versions of numpy\n",
    " #return np.stack((x,y,z),axis=1)\n",
    " return np.transpose(np.array([x,y,z]),(1,0,2))\n",
    "def polar2vec(r,th,z):\n",
    " xyz=np.array([r*np.cos(th),r*np.sin(th),z])\n",
    " return cycle(xyz,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to 'modulate' the thickness of the yarn slightly waving along its length. Given an initial radius 'r' of a single hair, we modify it slightly in a waving fashion to 'R'. An extra scale parameter will enable us to make loose loops in the hairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2R(zs,rs,th0=th0Default,scale=1):\n",
    " global rmin, rmax, s, relativetorsion,pi,th0Default\n",
    " tau=relativetorsion\n",
    " wl=relativepulse\n",
    " zunit=zs[-1]\n",
    " zA,rA=np.meshgrid(zs,rs)\n",
    " return rmin*rA+(rmax-rmin)/2*rA*(1+np.cos(th0+wl*2*pi*zA/zunit))*scale, zA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a good distribution of the hairs following the Cornell paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pdf(R):\n",
    " # exponential map [0,1] -> [1,0]\n",
    " pp=lambda r: (np.exp(1)-np.exp(r))/(np.exp(1)-1)\n",
    " # map [0,1]->[1-eps,eps]\n",
    " return (1-2*epsilon)*pp(R)**beta+epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the heavy lifting by the function 'strands': We define a set of M hairs of which a number (depending on loosness chance) will have increased radius, depicting loosened hairs. \n",
    "- First we distribute hairs equally over a circle, but add some random deviation of this regular pattern\n",
    "- Next we distribute the distance of each hair to the center according to the defined pdf-distribution\n",
    "- Then we randomly loosen each single hair, with the chance of a certain number of loose windings binomially depending on maxnumberofloosewindings and loopiness, the position of the loose loop is uniformly random.\n",
    "- Next we modulate the yarn width with the previously defined function and introduce the torsion\n",
    "- lastly we change the head of the hair: we turn off the torsion and make the hairs spread parabolically\n",
    "- We output a list of hairs, which in turn are a list of Cartesian coordinates we convert from the polar ones with the previously defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strands(zs,M,th0=th0Default):\n",
    " global th0Default, maxnumberofloosewindings,looseness,relativetorsion\n",
    " \n",
    " # define some custom variables\n",
    " tau=relativetorsion\n",
    " wl=relativepulse\n",
    " zunit=zs[-1]\n",
    " iis=np.arange(M)\n",
    "\n",
    " #add some jitter on the helicial pattern of the hairs\n",
    " ths=iis/M*2*pi\n",
    " ths+=(0.5-np.random.ranf((len(ths),)))/M*2*pi*jitter\n",
    "    \n",
    " #set of randomly distributed rvalues, according to pdf\n",
    " rOptions=np.linspace(0,1,1000)\n",
    " rProbs=pdf(rOptions)/sum(pdf(rOptions))\n",
    " rStrings=np.random.choice(rOptions,M,p=rProbs)*zunit\n",
    "    \n",
    " #pick loose windings\n",
    " windingnrs=np.arange(np.floor(tau).astype('uint32'))\n",
    " minimalZindices=np.searchsorted(zs,zunit*np.array([wl*(th0/2/pi+k) for k in windingnrs]))\n",
    " firstloosewinding=np.random.choice(windingnrs,M)\n",
    " nrofloosewindings=np.random.binomial(maxnumberofloosewindings,loopiness,M)\n",
    " looseStart=[np.searchsorted(zs,zunit*wl*(th0[k]/2/pi+firstloosewinding[k])) for k in iis]\n",
    " looseEnd=[np.searchsorted(zs,zunit*wl*(th0[k]/2/pi+np.minimum(firstloosewinding[k]+nrofloosewindings[k],windingnrs[-1]-1))) for k in iis]\n",
    " loosen=np.ones((M,len(zs)))\n",
    " for i in iis:\n",
    "  loosen[i,looseStart[i]:looseEnd[i]]=looseness\n",
    "\n",
    " # define polar coordinates of each point of every hair in the yarn\n",
    " R,Z=r2R(zs,rStrings,1,loosen)\n",
    " ths2=np.expand_dims(ths,axis=-1)+2*pi*tau*Z/zunit\n",
    "    \n",
    " # correct the uppermost points to open/desentangle the hairs there, like a muchroom\n",
    " R[:,-mushheight:]*=1+ (np.arange(mushheight)**2/mushheight**2)*(mushwidth-1)\n",
    " ths2[:,-mushheight:]=np.expand_dims(ths2[:,-mushheight],axis=-1)\n",
    "\n",
    " return polar2vec(R,ths2,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we alredy have a straight yarn with all equal length hairs, we want to add some shorter ones sticking out. The resulting yarn will contain contributions from both 'strands' and 'hairs'. \n",
    "- We let the hair exist between 1.5 and 2 times a standard winding, giiven by the original winding times relativetorsion\n",
    "- We distribute the max radius of each sticking hair between fluffyness x rmax and 2 x fluffyness x rmax, and the begin- and end-angle uniformly\n",
    "- We output again a list of points in Cartesian coordinates along the full yarn, and a 'chk' list to indicate wich parts are relevant. (For the rest we get unphysical/unimportant contributions that we'll have to ignore later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hairs(zs,M):\n",
    " zunit=zs[-1]\n",
    " skip=len(zs)/relativetorsion\n",
    " iis=np.arange(M)\n",
    "\n",
    " hairStart=np.random.choice(np.arange(len(zs)-1),M)\n",
    " hairEnd=[[zs[np.minimum(np.random.choice(np.arange(hairStart[i]+3*skip//2,hairStart[i]+2*skip)),len(zs)-1)]] for i in np.arange(len(iis))]\n",
    " hairStart=np.array([zs[k] for k in hairStart])\n",
    " zA,hS=np.meshgrid(zs,hairStart)\n",
    "\n",
    " rangeR=np.expand_dims(np.array([rmin*np.zeros((M,)),(np.random.rand(M,)+np.ones((M,)))*fluffyness*(rmax-0*rmin)])*zunit,axis=-1)\n",
    " rangeTh=np.expand_dims(np.random.rand(2,len(iis))*2*pi,axis=-1)\n",
    "\n",
    " f=np.array((zA-hS)/(hairEnd-hS))\n",
    " chk=(1+np.sign(f*(1-f)))/2\n",
    " return polar2vec((f*rangeR[1]+rangeR[0]),f*rangeTh[1]+rangeTh[0],zA), chk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All yarn contributions are now relative to a straight yarn core. We need to account for bending. Given the coordinates of the bended core, we first define the relative coordinates in a frame rotated according to the bending (technically: Frenet-Serret  vectors 't', 'n' and 'b'.).\n",
    "- We put the x- and y-coordinate, perpendicular to the straight yarn we defined before, along the normal directions 'n' and 'b', orthogonal to the curved yarn.\n",
    "- We output the old coordinates shifted by these two contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(oldvecs,newzs):\n",
    " tz=newzs[1:]-newzs[:-1]\n",
    " tz=np.concatenate((np.ones((1,3)),tz),axis=0)\n",
    " \n",
    " gz=tz[1:]-tz[:-1]\n",
    " gz=np.concatenate((np.ones((1,3)),gz),axis=0)\n",
    " nrm=np.expand_dims(np.linalg.norm(tz,axis=-1),axis=-1)\n",
    " nz=gz/nrm-tz*np.expand_dims(np.sum(gz*tz,axis=-1),axis=-1)/(nrm**3)\n",
    " nz[0]=np.ones((3,))\n",
    " tz=tz/nrm\n",
    " nrm=np.expand_dims(np.linalg.norm(nz,axis=-1),axis=-1)\n",
    " nz=nz/nrm\n",
    " nz[0]*=0\n",
    "\n",
    " bz=np.cross(tz,nz)\n",
    "    \n",
    " fs=np.expand_dims(stack(nz,bz,0*tz),axis=0)\n",
    " ov=np.expand_dims(oldvecs,axis=-1)\n",
    " return np.sum(ov*fs,axis=2)+newzs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make from a given (curved) list of points, a set of polylines (by which we mean a list of Cartesian points) forming the yarn we want. \n",
    "- First we defile the lengt of an equivalent straight yarn 'lPoly'\n",
    "- We warp all long strands around it by using subsequently the previously defined 'strands' (creating random sdistributed hairs) and 'warp' (curving them).\n",
    "- We do the same for the shorter hairs sticking out with 'hairs' and 'warp'. Remember that a number of contributions are unphysical, given by the accompanying check-list.\n",
    "- We combine all hairs and a corresponding global check-list, which selects all strands-points but only part of the hairs-points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly2polys(poly):\n",
    " global nStrands, nHairs, mushheight\n",
    " lPoly=np.sum(np.linalg.norm(poly[1:]-poly[:-1]))\n",
    "    \n",
    " zs=np.linspace(0,lPoly,len(poly))\n",
    " strandvecs=warp(strands(zs,nStrands),poly)\n",
    " chk1=np.ones((strandvecs.shape[0],strandvecs.shape[1]))\n",
    "\n",
    " hrs,chk2=hairs(zs,nHairs)\n",
    " hairvecs=warp(hrs,poly)\n",
    "\n",
    " allvecs=np.concatenate((strandvecs,hairvecs))\n",
    " allchks=np.concatenate((chk1,chk2))\n",
    " return allvecs,allchks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a single strand in Houdini, taking into account a check-list that might eliminate some unphysical points. Also, we oversampled the yarn to nicely capture the curvature in calculation, but we may however want to keep the redundant points out of Houdini by keeping only one in 'reducepoints'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newpoly(pointlist,chks):\n",
    " global mushheight\n",
    " poly=geo.createPolygon()\n",
    " poly.setIsClosed(0)\n",
    " i=0\n",
    " for (p,c) in zip(pointlist,chks):\n",
    "  cutoff=np.random.randint(len(pointlist)-mushheight,len(pointlist))\n",
    "  if (((c>0) and (i%reducePoints==0 or i==len(pointlist)-1)) and i<=cutoff):\n",
    "   pt=geo.createPoint()\n",
    "   pt.setPosition(p)\n",
    "   poly.addVertex(pt)\n",
    "  i+=1\n",
    " return poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a group of predefined polylines in Houdini that constitute our yarn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newyarn(polylist,chklist):\n",
    " global mushheight\n",
    " yarn=geo.createPrimGroup(\"yarn\")\n",
    " for (pointlist,chks) in zip(polylist,chklist):\n",
    "  poly=newpoly(pointlist,chks)\n",
    "  yarn.add(poly)\n",
    " return yarn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual workflow:\n",
    "    - We read in coordinates of given Houdini points\n",
    "    - We make sure the top is at the end (controlled by hand through flip)\n",
    "    - We create a set of individual hairs out of it as Houdini polylines, nicely curved around the original one, but with a check-list potentially eliminating some points.\n",
    "    - We group the hairs in a yarn as a Houdini primitive group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputPolyline=np.array([[p.position().x(),p.position().y(),p.position().z()] for p in geo.points()])\n",
    "if flip:\n",
    " inputPolyline=inputPolyline[::-1]\n",
    "polylist,chklist=poly2polys(inputPolyline)\n",
    "newyarn(polylist,chklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendum: generating twisting wires\n",
    "\n",
    "We want to be able to generate the polylines that are fed to the above script ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global relativetorsion,pi,  mushheight,mushwidth\n",
    "\n",
    "r0=node.parm('radius').eval()\n",
    "\n",
    "relativetorsion=node.parm('windingen').eval()\n",
    "\n",
    "nStrands=node.parm('strands').eval()\n",
    "\n",
    "mushheight=math.floor(node.parm('mushroomx').eval())\n",
    "mushwidth=node.parm('mushroomy').eval()\n",
    " \n",
    "pi=3.1415926\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def cycle(ar,shift):\n",
    "    return ar.transpose(np.roll(np.arange(len(ar.shape)),shift))\n",
    " \n",
    "def polar2vec(r,th,z):\n",
    "    xyz=np.array([r*np.cos(th),r*np.sin(th),z])\n",
    "    return cycle(xyz,-1)\n",
    "\n",
    "def stack(x,y,z):\n",
    "    #return np.stack((x,y,z),axis=1)\n",
    "    return np.transpose(np.array([x,y,z]),(1,0,2))\n",
    "\n",
    "def warp(oldvecs,newzs):\n",
    "    tz=newzs[1:]-newzs[:-1]\n",
    "    tz=np.concatenate((np.ones((1,3)),tz),axis=0) \n",
    "    nrmt=np.expand_dims(np.linalg.norm(tz,axis=-1),axis=-1)\n",
    "    \n",
    "    gz=tz[1:]-tz[:-1]\n",
    "    gz=np.concatenate((np.ones((1,3)),gz),axis=0)\n",
    "    nz=gz/nrmt-tz*np.expand_dims(np.sum(gz*tz,axis=-1),axis=-1)/(nrmt**3)\n",
    "    nz[0]=np.ones((3,))\n",
    "    nrmn=np.linalg.norm(nz,axis=-1)\n",
    "    tz /= nrmt\n",
    "    #regularize\n",
    "    tresh=0.0001\n",
    "    b0=np.cross(np.mean(tz,axis=0),np.mean(gz,axis=0))\n",
    "    b0 /= np.linalg.norm(b0)\n",
    "    if np.all(np.abs(b0)<10^(-8)):\n",
    "        b0=np.array([1,0,0])\n",
    "    if np.any(nrmn<tresh):\n",
    "        nz[nrmn<tresh]=np.cross(b0,tz[nrmn<tresh],axis=-1)\n",
    "    nrmn[nrmn<tresh]=1\n",
    "    ##########\n",
    "    nz *= np.expand_dims(np.sign(np.cross(tz,nz,axis=-1).dot(b0)) / nrmn,1)\n",
    "    nz[0]*=0\n",
    "    bz=np.cross(tz,nz)\n",
    "    fs=np.expand_dims(stack(nz,bz,0*tz),axis=0)\n",
    "    ov=np.expand_dims(oldvecs,axis=-1)\n",
    "    return np.sum(ov*fs,axis=2)+newzs\n",
    "\n",
    "def poly2polys0(poly,r0,M,tau,mushheight,mushwidth):\n",
    "    rs =np.ones((M,))*r0\n",
    "    lPoly=np.sum(np.linalg.norm(poly[1:]-poly[:-1]))\n",
    "    zs=np.linspace(0,lPoly,len(poly))\n",
    " \n",
    "    # define some custom variables\n",
    "    zunit=zs[-1]\n",
    "    ths=np.arange(M)/M*2*pi\n",
    "\n",
    "    # define polar coordinates of each point of every hair in the yarn\n",
    "    Z,R=np.meshgrid(zs,rs)\n",
    "    ths2=np.expand_dims(ths,axis=-1)+2*pi*tau*Z/zunit\n",
    "    \n",
    "    # correct the uppermost points to open/desentangle the hairs there, like a muchroom\n",
    "    R[:,-mushheight:]*=1+ (np.arange(mushheight)**2/mushheight**2)*(mushwidth-1)\n",
    "    ths2[:,-mushheight:]=np.expand_dims(ths2[:,-mushheight],axis=-1)\n",
    "\n",
    "    return warp(polar2vec(R,ths2,Z),poly)\n",
    "    \n",
    "\n",
    "def newpoly(pointlist,chks):\n",
    "    global mushheight\n",
    "    poly=geo.createPolygon()\n",
    "    poly.setIsClosed(0)\n",
    "    i=0\n",
    "    for p in pointlist:\n",
    "        pt=geo.createPoint()\n",
    "        pt.setPosition(p)\n",
    "        poly.addVertex(pt)\n",
    "        i+=1\n",
    "    return poly \n",
    "\n",
    "def newyarn(polylist,chklist,twisted):\n",
    "    global mushheight\n",
    "    yarn=geo.createPrimGroup(\"yarn\") \n",
    "    first=True\n",
    "    for (pointlist,chks,i) in zip(polylist,chklist,range(nStrands)):   \n",
    "        if first:\n",
    "            first = False\n",
    "            poly=geo.createPolygon()\n",
    "            poly.setIsClosed(0)\n",
    "            poly0=geo.points()\n",
    "            for (p,pos,j) in zip(poly0,pointlist,range(len(poly0))):\n",
    "                p.setPosition(pos)\n",
    "                poly.addVertex(p) \n",
    "        else:\n",
    "            poly=newpoly(pointlist,chks)\n",
    "        twisted[i].add(poly)\n",
    "        yarn.add(poly)\n",
    "    return yarn  \n",
    "   \n",
    "inputPolyline=np.array([[p.position().x(),p.position().y(),p.position().z()] for p in geo.points()])\n",
    "twisted=[]\n",
    "for i in range(nStrands):\n",
    "    twisted += [geo.createPrimGroup(\"twisted\"+str(i+1))]\n",
    "polylist=poly2polys0(inputPolyline,r0,nStrands,relativetorsion,mushheight,mushwidth)\n",
    "chklist = np.ones(polylist.shape[:2])\n",
    "newyarn(polylist,chklist,twisted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
